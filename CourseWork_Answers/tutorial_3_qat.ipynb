{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DeepWok/mase.git\n",
        "%cd mase\n",
        "!python3 -m pip install -e . -vvv\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSHhJ85o0XfM",
        "outputId": "764af994-af50-4951-df6f-bd1f6b39eb01"
      },
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            
            "Successfully installed mase-tools-1.0.0\n",
            "Removed build tracker: '/tmp/pip-build-tracker-if6a50zx'\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRj2X8zM0CbB"
      },
      "source": [
        "# Tutorial 3: Running Quantization-Aware Training (QAT) on Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN0BoV6D0CbE"
      },
      "source": [
        "In this tutorial, we'll build on top of Tutorial 2 by taking the Bert model fine tuned for sequence classification and running Mase's quantization pass. First, we'll run simple Post-Training Quantization (PTQ) and see how much accuracy drops. Then, we'll run some further training iterations of the quantized model (i.e. QAT) and see whether the accuracy of the trained quantized model approaches the accuracy of the original (full-precision) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jPJ7ullK0CbE"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"prajjwal1/bert-tiny\"\n",
        "tokenizer_checkpoint = \"bert-base-uncased\"\n",
        "dataset_name = \"imdb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALGLir7z0CbF"
      },
      "source": [
        "## Importing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8teZpt80CbF"
      },
      "source": [
        "If you are starting from scratch, you can create a MaseGraph for Bert by running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knIqL7HS0CbG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from chop import MaseGraph\n",
        "import chop.passes as passes\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "model.config.problem_type = \"single_label_classification\"\n",
        "\n",
        "mg = MaseGraph(\n",
        "    model,\n",
        "    hf_input_names=[\n",
        "        \"input_ids\",\n",
        "        \"attention_mask\",\n",
        "        \"labels\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
        "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v39JhYeU0CbG"
      },
      "source": [
        "If you have previously ran the tutorial on LoRA Finetuning, run the following cell to import the fine tuned checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zOvLYmS2Bld",
        "outputId": "2db67634-c1b9-49cc-8150-f0c8bea5a97b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13RmDl5p0CbG",
        "outputId": "c8af99d1-9e25-4953-8b8b-b24a45c26bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from chop import MaseGraph\n",
        "\n",
        "\n",
        "mg = MaseGraph.from_checkpoint(f\"/content/tutorial_2_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9AVFh0C0CbH"
      },
      "source": [
        "## Post-Training Quantization (PTQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcVV7vtX0CbH"
      },
      "source": [
        "Here, we simply quantize the model and evaluate the effect in its accuracy. First, let's evaluate the model accuracy before quantization (if you're coming from Tutorial 2, this should be the same as the post-LoRA evaluation accuracy). As seen in Tutorial 2, we can use the `get_tokenized_dataset` and `get_trainer` utilities to generate a HuggingFace `Trainer` instance for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "f67d985ca9db44feabf4dc41e36905ff",
            "0e7e5707ec0045ddbad3f4c9968d303a",
            "dfe79a3854874172aca6f9c289e32cdb",
            "b5e860eb416c441e86f28e9921a43f9f",
            "e78f44f1593b4c93af0a7d2e00122ebe",
            "cb70d09ce4fe4b7594463d70c5c325a0",
            "3227e26fbb7546468fd81cd2f2635357",
            "b27aaa3af99a4f1384c647a81eac6820",
            "4cefef13899b4aaf8965c5a86a0c90d9",
            "c1c4b269f0264507a91c6883cad3a520",
            "e0a6049758e44936b555743f8e099915"
          ]
        },
        "id": "cjFs73k70CbH",
        "outputId": "cc6a96a4-ea5a-47d9-e546-1041c70b7477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f67d985ca9db44feabf4dc41e36905ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 0.83816\n"
          ]
        }
      ],
      "source": [
        "from chop.tools import get_tokenized_dataset, get_trainer\n",
        "\n",
        "dataset, tokenizer = get_tokenized_dataset(\n",
        "    dataset=dataset_name,\n",
        "    checkpoint=tokenizer_checkpoint,\n",
        "    return_tokenizer=True,\n",
        ")\n",
        "\n",
        "trainer = get_trainer(\n",
        "    model=mg.model,\n",
        "    tokenized_dataset=dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    evaluate_metric=\"accuracy\",\n",
        ")\n",
        "\n",
        "# Evaluate accuracy\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0G5O8Pi0CbH"
      },
      "source": [
        "To run the quantization pass, we pass a quantization configuration dictionary as argument. This defines the quantization mode, numerical format and precision for each operator in the graph. We'll run the quantization in \"by type\" mode, meaning nodes are quantized according to their `mase_op`. Other modes include by name and by regex name. We'll quantize all activations, weights and biases in the model to fixed-point with the same precision. This may be sub-optimal, but works as an example. In future tutorials, we'll see how to run the `search` flow in `Mase` to find optimal quantization configurations to minimize accuracy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifXg5qTX0CbH"
      },
      "outputs": [],
      "source": [
        "import chop.passes as passes\n",
        "\n",
        "quantization_config = {\n",
        "    \"by\": \"type\",\n",
        "    \"default\": {\n",
        "        \"config\": {\n",
        "            \"name\": None,\n",
        "        }\n",
        "    },\n",
        "    \"linear\": {\n",
        "        \"config\": {\n",
        "            \"name\": \"integer\",\n",
        "            # data\n",
        "            \"data_in_width\": 8,\n",
        "            \"data_in_frac_width\": 4,\n",
        "            # weight\n",
        "            \"weight_width\": 8,\n",
        "            \"weight_frac_width\": 4,\n",
        "            # bias\n",
        "            \"bias_width\": 8,\n",
        "            \"bias_frac_width\": 4,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "mg, _ = passes.quantize_transform_pass(\n",
        "    mg,\n",
        "    pass_args=quantization_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq5l34IX0CbI"
      },
      "source": [
        "Let's evaluate the immediate effect of quantization on the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "8iApCXnl0CbI",
        "outputId": "ab91e435-e1f0-49cf-b299-a625bf98588d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 0.82344\n"
          ]
        }
      ],
      "source": [
        "trainer = get_trainer(\n",
        "    model=mg.model,\n",
        "    tokenized_dataset=dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    evaluate_metric=\"accuracy\",\n",
        ")\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sql97lEH0CbI"
      },
      "source": [
        "We can save the current checkpoint for future reference (optional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sbNEQBo0CbI",
        "outputId": "9e8e2187-5ae1-49d2-b525-babd3aa0a873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_ptq.pt, /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_ptq.mz\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_ptq.pt\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_ptq.mz\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "mg.export(f\"/content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_ptq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qzSi_6-0CbI"
      },
      "source": [
        "## Quantization-Aware Training (QAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flCe3cY50CbI"
      },
      "source": [
        "You should have seen in the last section that quantization can lead to a significant drop in accuracy. Next, we'll run QAT to evaluate whether this performance gap can be reduced. To run QAT in Mase, all you need to do is include the model back in your training loop after running the quantization pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dTtqn5ef0CbI",
        "outputId": "f7da324f-f81b-4ce2-821d-d5cb8d0693f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.394000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.384100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.382800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 03:57]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 0.84268\n"
          ]
        }
      ],
      "source": [
        "# Evaluate accuracy\n",
        "trainer.train()\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwSO5oPC0CbI"
      },
      "source": [
        "We can see the accuracy of the quantized model can match (or sometimes exceed) the full precision model, with a much lower memory requirement to store the weights. Finally, save the final checkpoint for future tutorials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyxYqndG0CbI",
        "outputId": "f7680c0c-ca27-4417-cef7-8102afed34d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_qat.pt, /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_qat.mz\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_qat.pt\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_qat.mz\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "mg.export(f\"/content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/Lab 1/Tutorial 3/tutorial_3_qat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "qY8Z29tD53a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from chop import MaseGraph\n",
        "import chop.passes as passes\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from chop.tools import get_tokenized_dataset, get_trainer\n",
        "\n",
        "\n",
        "\n",
        "# Define fixed-point widths to test\n",
        "fixed_point_widths = list(range(4, 33, 4))  # [4, 8, 12, 16, 20, 24, 28, 32]\n",
        "ptq_accuracies = []\n",
        "qat_accuracies = []\n",
        "\n",
        "for width in fixed_point_widths:\n",
        "    print(f\"\\n=== Testing Fixed-Point Width: {width} ===\")\n",
        "\n",
        "    # 1. Reload original model from checkpoint\n",
        "    mg = MaseGraph.from_checkpoint(f\"/content/drive/MyDrive/Colab Notebooks/IC/Advanced Deep Learning/tutorial_2_lora\")\n",
        "    # 2. Configure quantization for current width\n",
        "    quantization_config = {\n",
        "        \"by\": \"type\",\n",
        "        \"default\": {\"config\": {\"name\": None}},\n",
        "        \"linear\": {\n",
        "            \"config\": {\n",
        "                \"name\": \"integer\",\n",
        "                \"data_in_width\": width,\n",
        "                \"data_in_frac_width\": width - 2,\n",
        "                \"weight_width\": width,\n",
        "                \"weight_frac_width\": width - 2,\n",
        "                \"bias_width\": width,\n",
        "                \"bias_frac_width\": width - 2,\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # 3. Apply PTQ\n",
        "    mg, _ = passes.quantize_transform_pass(mg, pass_args=quantization_config)\n",
        "\n",
        "    # 4. Evaluate PTQ accuracy\n",
        "    ptq_trainer = get_trainer(\n",
        "        model=mg.model,\n",
        "        tokenized_dataset=dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        evaluate_metric=\"accuracy\",\n",
        "    )\n",
        "    ptq_results = ptq_trainer.evaluate()\n",
        "    ptq_acc = ptq_results[\"eval_accuracy\"]\n",
        "    ptq_accuracies.append(ptq_acc)\n",
        "    print(f\"PTQ Accuracy: {ptq_acc:.4f}\")\n",
        "\n",
        "    # 5. Configure QAT training\n",
        "    qat_trainer = trainer = get_trainer(\n",
        "        model=mg.model,\n",
        "        tokenized_dataset=dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        evaluate_metric=\"accuracy\",\n",
        "    )\n",
        "\n",
        "    # 6. Perform QAT\n",
        "    qat_trainer.train()\n",
        "\n",
        "    # 7. Evaluate QAT accuracy\n",
        "    qat_results = qat_trainer.evaluate()\n",
        "    qat_acc = qat_results[\"eval_accuracy\"]\n",
        "    qat_accuracies.append(qat_acc)\n",
        "    print(f\"QAT Accuracy: {qat_acc:.4f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fixed_point_widths, ptq_accuracies, \"b-o\", label=\"PTQ\")\n",
        "plt.plot(fixed_point_widths, qat_accuracies, \"r-o\", label=\"QAT\")\n",
        "plt.xlabel(\"Fixed-Point Width (bits)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"IMDb Classification Accuracy vs. Quantization Precision\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(fixed_point_widths)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_H6J7B2i55xQ",
        "outputId": "b8df1f19-6860-4f94-b3c3-3e7471848712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Testing Fixed-Point Width: 4 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.5000\n",
            "\n",
            "=== Testing Fixed-Point Width: 8 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.410700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.404800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.394300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.384000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8388\n",
            "\n",
            "=== Testing Fixed-Point Width: 12 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.407800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.378300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8402\n",
            "\n",
            "=== Testing Fixed-Point Width: 16 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.407800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8402\n",
            "\n",
            "=== Testing Fixed-Point Width: 20 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.407800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8402\n",
            "\n",
            "=== Testing Fixed-Point Width: 24 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.407800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8402\n",
            "\n",
            "=== Testing Fixed-Point Width: 28 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:01, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.407800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/ir/graph/mase_graph.py:380: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model = torch.load(f)\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
            "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8402\n",
            "\n",
            "=== Testing Fixed-Point Width: 32 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTQ Accuracy: 0.8093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.407800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Accuracy: 0.8402\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding how many epoch of training until overfitting"
      ],
      "metadata": {
        "id": "zJ3Y4hzEtYBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from chop import MaseGraph\n",
        "from chop.tools import get_tokenized_dataset, get_trainer\n",
        "\n",
        "checkpoint = \"prajjwal1/bert-tiny\"\n",
        "tokenizer_checkpoint = \"bert-base-uncased\"\n",
        "dataset_name = \"imdb\"\n",
        "\n",
        "\n",
        "# Load dataset and tokenizer\n",
        "dataset, tokenizer = get_tokenized_dataset(\n",
        "    dataset=dataset_name,\n",
        "    checkpoint=tokenizer_checkpoint,\n",
        "    return_tokenizer=True,\n",
        ")\n",
        "\n",
        "# Store accuracy per epoch\n",
        "accuracy_results = []\n",
        "\n",
        "# Training loop for incremental training\n",
        "for epoch in range(1, 11):\n",
        "    print(f\"\\nTraining Epoch {epoch}...\")\n",
        "\n",
        "    # Apply LoRA (if not already applied)\n",
        "    mg, _ = passes.insert_lora_adapter_transform_pass(\n",
        "        mg,\n",
        "        pass_args={\n",
        "            \"rank\": 6,\n",
        "            \"alpha\": 1.0,\n",
        "            \"dropout\": 0.5,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = get_trainer(\n",
        "        model=mg.model,\n",
        "        tokenized_dataset=dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        evaluate_metric=\"accuracy\",\n",
        "        num_train_epochs=1,  # Train for one epoch at a time\n",
        "    )\n",
        "\n",
        "    # Train incrementally\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate and store results\n",
        "    eval_results = trainer.evaluate()\n",
        "    accuracy = eval_results[\"eval_accuracy\"]\n",
        "    accuracy_results.append(accuracy)\n",
        "    print(f\"Epoch {epoch} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Fuse LoRA weights after training\n",
        "    mg, _ = passes.fuse_lora_weights_transform_pass(mg)\n",
        "\n",
        "# Plot accuracy trend over epochs\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 11), accuracy_results, marker='o', linestyle='-')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs. Training Epochs (LoRA)\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ab3262bda32a4b149dd214907a41c567",
            "7948b23c28c445ab8ccd6317a3b9f550",
            "a25101014f674ca689987aacaeffff97",
            "187f79e2c99a49c5b6fa27ae4b694cd0",
            "98fb298595b340dc9f34164b45be9b07",
            "e55ebdb8ec2e49d2a184873650768d3f",
            "903082766835488c8910ab127fbdac6f",
            "3a8b1393d5974c64a673d80f56f3cf74",
            "83c09acf1afd492dbf57662a952a66f4",
            "0898671fd9e64327a3d152024fb02c45",
            "4f34de22af384d6693f9fb99a5fff795"
          ]
        },
        "id": "aBU1zNQxtjuT",
        "outputId": "9dcb0bca-9b50-4c32-9a46-0c53875423e3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab3262bda32a4b149dd214907a41c567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Epoch 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:08, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.383700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.387400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.384900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.376800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Accuracy: 0.8452\n",
            "\n",
            "Training Epoch 2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:09, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.356300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.367800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.374500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.360400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.377200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.373200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Accuracy: 0.8505\n",
            "\n",
            "Training Epoch 3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:08, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.337700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.354500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.361800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.352200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.374100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.375100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Accuracy: 0.8534\n",
            "\n",
            "Training Epoch 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:06, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.316700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.346000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.342300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.372100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.381100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:25]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Accuracy: 0.8539\n",
            "\n",
            "Training Epoch 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:09, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.294200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.325200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.335000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.332400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.372600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Accuracy: 0.8544\n",
            "\n",
            "Training Epoch 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.268400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.292500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.323000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.329400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.378200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Accuracy: 0.8545\n",
            "\n",
            "Training Epoch 7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.239000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.261200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.322100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.385800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.415300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Accuracy: 0.8547\n",
            "\n",
            "Training Epoch 8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:08, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.211300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.232700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.299600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.317200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.391400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:26]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Accuracy: 0.8542\n",
            "\n",
            "Training Epoch 9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:10, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.185800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.208800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.276800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.305400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.391400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.444800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_query, target: bert.encoder.layer.0.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_key, target: bert.encoder.layer.0.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_self_value, target: bert.encoder.layer.0.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_attention_output_dense, target: bert.encoder.layer.0.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_intermediate_dense, target: bert.encoder.layer.0.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_0_output_dense, target: bert.encoder.layer.0.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_query, target: bert.encoder.layer.1.attention.self.query with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_key, target: bert.encoder.layer.1.attention.self.key with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_self_value, target: bert.encoder.layer.1.attention.self.value with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_attention_output_dense, target: bert.encoder.layer.1.attention.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_intermediate_dense, target: bert.encoder.layer.1.intermediate.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_encoder_layer_1_output_dense, target: bert.encoder.layer.1.output.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: bert_pooler_dense, target: bert.pooler.dense with LoRALinear module.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mReplaced node: classifier, target: classifier with LoRALinear module.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Accuracy: 0.8527\n",
            "\n",
            "Training Epoch 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 01:10, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.191100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.251700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.293800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.399400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.462700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.0.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.query.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.key.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.self.value.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.attention.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.intermediate.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.encoder.layer.1.output.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for bert.pooler.dense.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[34mFusing LoRALinear weights for classifier.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Accuracy: 0.8506\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f67d985ca9db44feabf4dc41e36905ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e7e5707ec0045ddbad3f4c9968d303a",
              "IPY_MODEL_dfe79a3854874172aca6f9c289e32cdb",
              "IPY_MODEL_b5e860eb416c441e86f28e9921a43f9f"
            ],
            "layout": "IPY_MODEL_e78f44f1593b4c93af0a7d2e00122ebe"
          }
        },
        "0e7e5707ec0045ddbad3f4c9968d303a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb70d09ce4fe4b7594463d70c5c325a0",
            "placeholder": "​",
            "style": "IPY_MODEL_3227e26fbb7546468fd81cd2f2635357",
            "value": "Map: 100%"
          }
        },
        "dfe79a3854874172aca6f9c289e32cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b27aaa3af99a4f1384c647a81eac6820",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cefef13899b4aaf8965c5a86a0c90d9",
            "value": 25000
          }
        },
        "b5e860eb416c441e86f28e9921a43f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1c4b269f0264507a91c6883cad3a520",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a6049758e44936b555743f8e099915",
            "value": " 25000/25000 [00:09&lt;00:00, 2701.72 examples/s]"
          }
        },
        "e78f44f1593b4c93af0a7d2e00122ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb70d09ce4fe4b7594463d70c5c325a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3227e26fbb7546468fd81cd2f2635357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b27aaa3af99a4f1384c647a81eac6820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cefef13899b4aaf8965c5a86a0c90d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1c4b269f0264507a91c6883cad3a520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a6049758e44936b555743f8e099915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab3262bda32a4b149dd214907a41c567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7948b23c28c445ab8ccd6317a3b9f550",
              "IPY_MODEL_a25101014f674ca689987aacaeffff97",
              "IPY_MODEL_187f79e2c99a49c5b6fa27ae4b694cd0"
            ],
            "layout": "IPY_MODEL_98fb298595b340dc9f34164b45be9b07"
          }
        },
        "7948b23c28c445ab8ccd6317a3b9f550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e55ebdb8ec2e49d2a184873650768d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_903082766835488c8910ab127fbdac6f",
            "value": "Map: 100%"
          }
        },
        "a25101014f674ca689987aacaeffff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8b1393d5974c64a673d80f56f3cf74",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83c09acf1afd492dbf57662a952a66f4",
            "value": 50000
          }
        },
        "187f79e2c99a49c5b6fa27ae4b694cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0898671fd9e64327a3d152024fb02c45",
            "placeholder": "​",
            "style": "IPY_MODEL_4f34de22af384d6693f9fb99a5fff795",
            "value": " 50000/50000 [00:19&lt;00:00, 2701.45 examples/s]"
          }
        },
        "98fb298595b340dc9f34164b45be9b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55ebdb8ec2e49d2a184873650768d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "903082766835488c8910ab127fbdac6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a8b1393d5974c64a673d80f56f3cf74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c09acf1afd492dbf57662a952a66f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0898671fd9e64327a3d152024fb02c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f34de22af384d6693f9fb99a5fff795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
